## 额外数据分析报告

### IMDB评论分析
### 数据集来源：IMDB Dataset of 50K Movie Reviews     
网址：https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews?resource=download

### 数据说明：
#### 1.数据获取与筛选
原数据集有五万条数据，为方便截取其前2000条进行分析；   

原数据仅binary标注，只区分positive和negative，但是要求使用sentiStrength的trinary分析，所以在对比时去掉了sentiStrength得分为0的数据(仅1条)。

#### 2.数据分析
最终的1999条数据中，有1308条是符合人工标注的结果的，正确率为0.6543； 

由于对照组的软工文本网上没有找到合适数据，采用了助教提供的StackOverflow的评论（支持正负0三元），
其4423条数据中有3607条符合人工标注，其正确率为0.8155； 

为了和IMDB评论数据对比，去掉对照组中分值为0的值后，剩余的3262条数据中有2530条数据符合，正确率为0.7756。

根据此数据，IMDB评论的符合值远远低于软工文本，由于去掉了零值，另外适用scale选项考虑从极性分析：

在绝对值较小（1、2）的文本中：IMDB在1906条数据中有1223条数据匹配，正确率0.6417；软工文本在122条数据中有74条数据匹配，正确率0.6065      

在绝对值较大（3、4）的文本中：IMDB在94条数据中有85条数据匹配，正确率0.9253；软工文本在3146条数据中有2456条数据匹配，正确率0.7807        

由此可以看出，影视评论中总体情感偏中立占绝大多数，极少数情感非常强烈；而软工文本中情感强烈占大多数（而其中负面情绪的占比稍多一点，0.5232），情感中立占少数。

究其原因，推测如下：虽然同样是论坛情况，影视评论大多数是观影感受，相对客观；而此处软工文本（StackOverflow）大多数是遇到问题求助，或是指出一些项目中的问题，主观情绪较强。
而在双方较主要的方面，情感较强的相对情感较弱的就较容易判断一些（0.7807>0.6417）   

#### 3.可能的优化手段
对于软工文本中，由于情感较强的错误率反而较高，说明可能是一些关键词语或者句式理解反了，
查看后发现在这其中629个错误中例如"no worries",":)"等短语或表情出现次数较多（"no worries"出现了46次），可能的优化方式是更新相应的词典，弥补一些出现多且容易反义的词语；       

软工文本分析由于使用的是助教给出数据，在"助教数据分析"中详细展开。     

对于此社交文本中，绝大多数是情感较中立的数据，说明可能是段落中的一部分词语得分不当，观察分析后，发现有以下几种类型：

1.特殊情况下用语：如看电影时"nervous"不一定赋负分，评论恐怖电影时"scary","horror"也不一定赋负分等。这种情况可能的优化方式是，设定一些常见的情况
（比如日常社交，论坛评论，工作询问等），并根据此选择对应词典       

2.词性错误：例如"any other like it"中like被当成动词赋了+1分，"some kind of a ... array"中kind被当成形容词赋+1分等等。    

在现有基础上（除nlp等方法），可能的优化方式是对于有多种词性的词语建立list，在赋分时根据上下文特判其词性再确定得分。（如果重构代码则可考虑桥接模式等设计词语列表）    

3.句式错误：例如"it's not ... or boring" 中boring没有被认为是否定（not 后的形容词分值会被无效，但没有适用到boring),

现有基础上可能增加一些固定句式,在出现这些句式时为句式的各个部分都设定特性（如此处not...or,两个都设定为negatedWord）

------



### Twitter额外数据分析

#### 前言：本部分主要使用Sentiment的三元分析法对额外2000条Twitter数据进行了分析，并和人工标注情绪值进行了分析。

#### 数据说明：本次分析的2000条Twitter节选自数据集http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22的前2000条，标1代表正面，标-1代表负面，没有中立情绪值0.

**一、数据结果分析**

我们这次分析的目标是为了确定为了确保去除Twitter数据集没有中立情绪0的偏差，我们把Sentiment中情绪值为0的单元行筛选去掉，只对比正负面情绪。剩余数据共1396个，在比较单元格差异后，我们把不匹配的数据标黄。

如下图所示：

![匹配率.png](https://s2.loli.net/2023/03/27/vOUmPuSwWlsjkQn.png)

经对比后，1396条数据中有426条数据情绪值不匹配，970条数据匹配Sentiment分析的数据结果与人工标注集的匹配率约为69.48%。就准确率来看，对于二元判断（50%概率），Sentiment的结果不甚理想。

**二、可能的原因分析**

1.该数据集为Twitter社交文本，包含了大量的网络用语或新式缩写，Sentiment的字典的覆盖面太小或过时导致无法理解其中的含义。

2.社交文本中许多情况下并不会直观地用一些情绪词汇来表达自己的正负面心情，而需要结合上下文语句和背景共同判断，对于Sentiment这一依靠字典判断地程序来说较为困难。

3.一些特殊标点符号，如”...“，ID72所示text，用户是在自嘲自己太过友善心不够软，表达了一种自嘲和失落的负面情绪，而Sentiment分析了其中的"lol"却并未结合上下文"..."或”well“转折判断。因此判断错误

4.社交文本中一些单词会连续书写其中某个字母或对某一单词全部大写加强语气，但是Sentiment无法判断，因其不在字典中或大写自动转换小写。如ID22的"wompppp"是一种口头表达表示亮度突然增大许多，同时连写p加强了不满情绪。

5.社交文本中包含更多生活专用名词或特殊词汇，如有人模仿某一动漫人物说话表示开心，但是Sentiment字典未收录，因此无法判断。

#### 总结：Sentiment准确率不够高的可能原因是

1）字典覆盖面不够广，若想通过枚举的形式而非机器学习的形式进行则需要覆盖面更大，收录更多的字典

2）Sentiment的特点是通过字典为单词、字符、短语、标点等赋予情绪值进行分析，无法对社交中的复杂上下文环境进行分析，也就无法判断出非直接的自嘲、讽刺等情绪。